input {
  # TCP input for Laravel logs
  tcp {
    port => 5000
    codec => json
    tags => ["laravel"]
  }

  # Beats input (optional - for Filebeat if needed later)
  beats {
    port => 5044
    tags => ["beats"]
  }

  # Kafka input - Monitor Kafka topics
  kafka {
    bootstrap_servers => "kafka:9092"
    topics => ["product_events", "order-events", "user-events", "product_events_dlq"]
    codec => "plain"
    group_id => "logstash-consumer-group"
    consumer_threads => 1
    tags => ["kafka_topic"]
    decorate_events => true
  }
}

filter {
    if "elasticsearch" in [tags] {
      if ![timestamp] {
        mutate { add_field => { "timestamp" => "%{@timestamp}" } }
      }

      mutate {
        rename => { "host" => "host_info" }
      }

      if [level] {
        mutate { lowercase => [ "level" ] }
      }

      if ![env] {
        mutate { add_field => { "env" => "local" } }
      }
    }

    # Parse Laravel logs
    # Tag beats input redis lines as laravel so they flow to laravel index
    # Filebeat writes the custom field at the top-level (fields_under_root=true),
    # so check [source_app] instead of [fields][source_app].
    if "beats" in [tags] and [source_app] == "redis" {
      mutate { add_tag => ["redis"] }
    }

     if "redis" in [tags] {
      # Add timestamp if not present
      if ![timestamp] {
        mutate {
          add_field => { "timestamp" => "%{@timestamp}" }
        }
      }

      # Avoid Elasticsearch mapping issues: Filebeat adds a `host` object, but the
      # laravel index expects host as text in some templates â€” rename to host_info
      # so we don't attempt to index an object into a text field.
      mutate {
        rename => { "host" => "host_info" }
      }

      # Extract log level
      if [level] {
        mutate {
          lowercase => [ "level" ]
        }
      }

      # Add environment field
      if ![env] {
        mutate {
          add_field => { "env" => "local" }
        }
      }

      # Geoip if IP present
      if [ip] {
        geoip {
          source => "ip"
          target => "geoip"
        }
      }
    }

    if "laravel" in [tags] {
      # Add timestamp if not present
      if ![timestamp] {
        mutate {
          add_field => { "timestamp" => "%{@timestamp}" }
        }
      }

      # Avoid Elasticsearch mapping issues: Filebeat adds a `host` object, but the
      # laravel index expects host as text in some templates â€” rename to host_info
      # so we don't attempt to index an object into a text field.
      mutate {
        rename => { "host" => "host_info" }
      }

      # Extract log level
      if [level] {
        mutate {
          lowercase => [ "level" ]
        }
      }

      # Add environment field
      if ![env] {
        mutate {
          add_field => { "env" => "local" }
        }
      }

      # Geoip if IP present
      if [ip] {
        geoip {
          source => "ip"
          target => "geoip"
        }
      }
    }

    # Parse Kafka messages
    if "kafka_topic" in [tags] {
      # First try to parse JSON from message field using the json filter
      json {
        source => "message"
        target => "kafka_message"
        # do not add failure tags here; we'll handle fallback parsing below
        tag_on_failure => []
      }

      # If json filter didn't populate kafka_message (some producers double-encode JSON
      # or include additional quoting), attempt a robust parse with ruby as a fallback.
      if ![kafka_message] {
        # Simplified fallback: don't attempt complex double-decode here to avoid
        # Logstash configuration quoting issues. Producers that double-encode
        # should be fixed upstream; for now tag failures so we can continue.
        ruby {
          code => 'event.tag("_jsonparsefailure")'
        }
      }

      mutate {
        add_field => {
          "source_type" => "kafka_topic"
          "kafka_topic" => "%{[@metadata][kafka][topic]}"
        }
      }
    }

    # Parse Nginx access logs (if needed)
    if "nginx" in [tags] {
      grok {
        match => { "message" => "%{COMBINEDAPACHELOG}" }
      }
      date {
        match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
      }
    }

  }

output {
    if "elasticsearch" in [tags] {
      elasticsearch {
        hosts => ["http://elasticsearch:9200"]
        index => "elasticsearch-logs-%{+YYYY.MM.dd}"
        user => "${LOGSTASH_ES_USERNAME}"
        password => "${LOGSTASH_ES_PASSWORD}"
      }
    }

    if "redis" in [tags] {
      elasticsearch {
        hosts => ["http://elasticsearch:9200"]
        index => "redis-logs-%{+YYYY.MM.dd}"
        user => "${LOGSTASH_ES_USERNAME}"
        password => "${LOGSTASH_ES_PASSWORD}"
      }
    }
    # Debug: print kafka events to Logstash stdout for troubleshooting
    if "kafka_topic" in [tags] {
      stdout {
        codec => rubydebug
      }
    }
    # Laravel logs to daily indices
    if "laravel" in [tags] {
      elasticsearch {
        hosts => ["http://elasticsearch:9200"]
        index => "laravel-logs-%{+YYYY.MM.dd}"
        user => "${LOGSTASH_ES_USERNAME}"
        password => "${LOGSTASH_ES_PASSWORD}"
      }
    }

    # Kafka messages to kafka-events index
    if "kafka_topic" in [tags] {
      elasticsearch {
        hosts => ["http://elasticsearch:9200"]
        index => "kafka-events-%{+YYYY.MM.dd}"
        user => "${LOGSTASH_ES_USERNAME}"
        password => "${LOGSTASH_ES_PASSWORD}"
      }
    }

    # Default output for other sources
    if "laravel" not in [tags] and "kafka_topic" not in [tags] and "redis" not in [tags] and "elasticsearch" not in [tags] {
      elasticsearch {
        hosts => ["http://elasticsearch:9200"]
        index => "logstash-%{+YYYY.MM.dd}"
        user => "${LOGSTASH_ES_USERNAME}"
        password => "${LOGSTASH_ES_PASSWORD}"
      }
    }

    # Debug output (optional - comment out in production)
    stdout {
      codec => rubydebug
    }
  }
